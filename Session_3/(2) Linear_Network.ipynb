{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open All Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/analytics-club-iitm/DL-Marathon/blob/main/intro/pytorch_intro.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([-0.9226, -0.4759, -0.8283, -0.0429, -0.2678])\n"
     ]
    }
   ],
   "source": [
    "# creating a tensor\n",
    "\n",
    "# zero tensor\n",
    "zeros = torch.zeros(5)\n",
    "print(zeros)\n",
    "# ones\n",
    "ones = torch.ones(5)\n",
    "print(ones)\n",
    "# random normal\n",
    "random = torch.randn(5)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7086,  0.5833, -0.6784],\n",
      "        [ 0.0612,  0.2426,  0.0216],\n",
      "        [-0.2069,  0.6905, -1.2957]])\n",
      "tensor([[[-0.2458, -1.7286,  0.1315],\n",
      "         [ 0.5496, -0.0911,  0.1577],\n",
      "         [ 0.2738,  2.0827,  0.0027]],\n",
      "\n",
      "        [[ 1.5192, -0.0942, -0.0751],\n",
      "         [ 0.1414, -0.1927,  1.0638],\n",
      "         [-0.5661, -0.2539,  0.4815]],\n",
      "\n",
      "        [[ 0.2348, -1.2164, -1.5791],\n",
      "         [-1.2979, -0.4811, -1.1629],\n",
      "         [-1.3320,  0.9052,  1.1341]]])\n"
     ]
    }
   ],
   "source": [
    "# multi dimenstional tensors\n",
    "\n",
    "# 2D\n",
    "two_dim = torch.randn((3, 3))\n",
    "print(two_dim)\n",
    "# 3D \n",
    "three_dim = torch.randn((3, 3, 3))\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([-0.7086,  0.0612, -0.2069])\n",
      "tensor([-0.7086,  0.5833, -0.6784])\n"
     ]
    }
   ],
   "source": [
    "# tensor shapes and axes\n",
    "\n",
    "print(zeros.shape)\n",
    "print(two_dim.shape)\n",
    "print(three_dim.shape)\n",
    "\n",
    "# zeroth axis - rows\n",
    "print(two_dim[:, 0])\n",
    "# first axis - columns\n",
    "print(two_dim[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3502, -2.2359,  0.3922, -1.3882],\n",
      "        [-0.0369, -0.3794,  0.0401,  0.1474],\n",
      "        [-1.3354, -0.1249, -0.4322,  0.1471]])\n",
      "tensor([[ 2.3502, -2.2359,  0.3922, -1.3882, -0.0369, -0.3794],\n",
      "        [ 0.0401,  0.1474, -1.3354, -0.1249, -0.4322,  0.1471]])\n",
      "tensor(2.3502)\n",
      "tensor(-0.2380)\n",
      "tensor([ 2.3502, -0.1249,  0.3922,  0.1474]) tensor([0, 2, 0, 1])\n",
      "tensor([2.3502, 0.1474, 0.1471]) tensor([0, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# some other operations\n",
    "\n",
    "# reshape\n",
    "a = torch.randn((3, 4))\n",
    "print(a)\n",
    "a_reshaped = a.view(2, 6)\n",
    "print(a_reshaped)\n",
    "\n",
    "# reshape with -1\n",
    "a_reshaped = a.view(4, -1)\n",
    "a_reshaped = a.view(-1)\n",
    "\n",
    "# max, mean\n",
    "val = torch.max(a)\n",
    "print(val)\n",
    "a_mean = torch.mean(a)\n",
    "print(a_mean)\n",
    "\n",
    "# along various axes\n",
    "val, ind = torch.max(a, dim=0)\n",
    "print(val, ind)\n",
    "val, ind = torch.max(a, dim=1)\n",
    "print(val, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# cpu-gpu\n",
    "a = torch.randn((3, 4))\n",
    "print(a.device)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "a = a.to(device)\n",
    "print(a.device)\n",
    "\n",
    "# a more generic code\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# torch to numpy\n",
    "\n",
    "a = a.cpu().numpy()\n",
    "print(type(a))\n",
    "\n",
    "# numpy to torch\n",
    "import numpy as np\n",
    "a = np.ones((3, 3))\n",
    "a = torch.from_numpy(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# basic back prop\n",
    "\n",
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 (w)\n",
    "print(w.grad)    # w.grad = 1 (x)\n",
    "print(b.grad)    # b.grad = 1 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=3, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# defining layers\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "layer1 = nn.Linear(3, 3)\n",
    "print(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[ 0.2669,  0.3833,  0.0285],\n",
      "        [-0.4717, -0.1962,  0.1754]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([0.2469, 0.0240], requires_grad=True)\n",
      "loss:  0.6296709775924683\n",
      "dL/dw:  tensor([[ 0.5352,  0.3971, -0.3497],\n",
      "        [-0.3591,  0.0276,  0.2815]])\n",
      "dL/db:  tensor([-0.4149,  0.1274])\n",
      "loss after 1 step optimization:  0.6201015114784241\n"
     ]
    }
   ],
   "source": [
    "# Create tensors of shape (10, 3) and (10, 2).\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "# Build loss function and optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass.\n",
    "pred = linear(x)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.item())\n",
    "\n",
    "# Backward pass.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "# 1-step gradient descent.\n",
    "optimizer.step()\n",
    "\n",
    "# Print out the loss after 1-step gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 11993088/170498071 [00:19<04:21, 607132.23it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xerefic/Downloads/TKMSession_Notes/Session_3/(2) Linear_Network.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, transforms\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39m# use existing datasets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=3'>4</a>\u001b[0m \u001b[39m# Download and construct CIFAR-10 dataset.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=4'>5</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mCIFAR10(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=5'>6</a>\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=6'>7</a>\u001b[0m     train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=7'>8</a>\u001b[0m     transform\u001b[39m=\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mToTensor(), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=8'>9</a>\u001b[0m     download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=11'>12</a>\u001b[0m \u001b[39m# Fetch one data pair (read data from disk).\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000011?line=12'>13</a>\u001b[0m image, label \u001b[39m=\u001b[39m val_dataset[\u001b[39m10\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39m=\u001b[39m train  \u001b[39m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/cifar.py:141\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFiles already downloaded and verified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m download_and_extract_archive(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, filename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, md5\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtgz_md5)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/utils.py:430\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[1;32m    428\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[0;32m--> 430\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[1;32m    432\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    433\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/utils.py:141\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m url \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m fpath)\n\u001b[0;32m--> 141\u001b[0m     _urlretrieve(url, fpath)\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m (urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mURLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m url[:\u001b[39m5\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/utils.py:35\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mlength) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mlambda\u001b[39;00m: response\u001b[39m.\u001b[39mread(chunk_size), \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     36\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m     37\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torchvision/datasets/utils.py:35\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mlength) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mlambda\u001b[39;00m: response\u001b[39m.\u001b[39;49mread(chunk_size), \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     36\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m     37\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# use existing datasets\n",
    "# Download and construct CIFAR-10 dataset.\n",
    "val_dataset = datasets.CIFAR10(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    transform=transforms.ToTensor(), \n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Fetch one data pair (read data from disk).\n",
    "image, label = val_dataset[10]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "plt.show()\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32]) torch.Size([64])\n",
      "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Data loader (this provides queues and threads in a very simple way).\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# how data is loaded in the backend\n",
    "# When iteration starts, queue and thread start to load data from files.\n",
    "data_iter = iter(loader)\n",
    "# Mini-batch images and labels.\n",
    "images, labels = data_iter.next()\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "# Usage of the data loader is as below.\n",
    "for images, labels in loader:\n",
    "    # Training code should be written here.\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Defining a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        return None\n",
    "    def __len__(self):\n",
    "        # return length of the dataset\n",
    "        return 0 # here 0 because there are no elements\n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "custom_loader = torch.utils.data.DataLoader(\n",
    "    dataset=custom_dataset,\n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4268, 0.4466, 0.0190],\n",
      "        [0.6959, 0.7932, 0.0326]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# defining models\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # 1. initialize all the model layers (eg: nn.Linear(), nn.Conv2d(),etc)\n",
    "        self.layer1 = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # 1. pass through the required layers and perform the necessary operations\n",
    "        # eg: out = self.layer1(x)\n",
    "        # return final output\n",
    "        out = self.layer1(inp)\n",
    "        return out\n",
    "\n",
    "model = CustomModel().to(device)\n",
    "inp = torch.randn((2, 3)).to(device)\n",
    "output = model(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and load the entire model.\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "model.load_state_dict(torch.load('model.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (EXTREME OVERKILL CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'XYSet' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'XYSet' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'XYSet' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'XYSet' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 6444) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1060\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1061\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 6444) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/xerefic/Downloads/TKMSession_Notes/Session_3/(2) Linear_Network.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000017?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m200\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000017?line=38'>39</a>\u001b[0m     loss_cntr \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000017?line=39'>40</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000017?line=40'>41</a>\u001b[0m         x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat(), y\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xerefic/Downloads/TKMSession_Notes/Session_3/%282%29%20Linear_Network.ipynb#ch0000017?line=41'>42</a>\u001b[0m         y_pred \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:578\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    579\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    581\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    582\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1256\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1255\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1256\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1259\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1222\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1223\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1224\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/miniconda3/envs/torch-nightly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1073\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1072\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1073\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1075\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 6444) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# SUPER UNWANTEDLY LARGE LINEAR REGRESSION CODE (HOWEVER WILL GIVE U AN OVERALL IDEA SO YEAH)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class XYSet(Dataset):\n",
    "    def __init__(self):\n",
    "        # toy dataset\n",
    "        data = np.genfromtxt(\"https://raw.githubusercontent.com/MukundVarmaT/PythonMLworkshop/master/data.csv\", delimiter=\",\")\n",
    "        self.x, self.y = data[:,[0]], data[:, [1]]\n",
    "    def __getitem__(self, indx):\n",
    "        return self.x[indx], self.y[indx]\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "class LinReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinReg, self).__init__()\n",
    "        self.layer = nn.Linear(1, 1)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "dset = XYSet()\n",
    "loader = DataLoader(dset, batch_size=8, num_workers=4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LinReg().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(200):\n",
    "    loss_cntr = []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device).float(), y.to(device).float()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_cntr.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 200, np.mean(loss_cntr)))\n",
    "\n",
    "# Plot the graph\n",
    "predicted = model(torch.from_numpy(dset.x).to(device).float()).cpu().detach().numpy()\n",
    "plt.plot(dset.x, dset.y, 'ro', label='Original data')\n",
    "plt.plot(dset.x, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "96f3b34ada46ee5e21a62afe05346301afc78e14b46989186e799e4b1d5dd107"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
