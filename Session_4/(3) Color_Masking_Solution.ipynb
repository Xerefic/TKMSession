{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B2_color_masking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ8jVbh9FPPN"
      },
      "source": [
        "# Task 1: Simple Detection and Tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjgqQrztFo3a"
      },
      "source": [
        "# Note: this is colab specific notebook\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!mkdir media/\n",
        "!wget -nv \"https://imgur.com/RfwDZci.png\" -O \"media/fruit.png\"\n",
        "!gdown \"https://drive.google.com/uc?id=1MTXoD5TjltFBgLQHHFa1zVzHZwh3Z5Ti\" -O media/track1.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_MeNQtkN6gh"
      },
      "source": [
        "Our task will be detect and localize, i.e find the positions of the cherries in the image and draw a bounding box around them.\n",
        "\n",
        "The image has already been saved at `media/fruit.png`\n",
        "\n",
        "![](https://imgur.com/RfwDZci.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITvsSUOlO3GE"
      },
      "source": [
        "### Our action plan\n",
        "\n",
        "- Read the color image\n",
        "- Convert it to HSV\n",
        "- Only take the red color part of the image using thresholding\n",
        "- Find outlines of each cherry\n",
        "- Draw a box around it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ozCqfMPavt"
      },
      "source": [
        "#### Why HSV?\n",
        "\n",
        "The answer is that unlike RGB, HSV separates luma, or the image intensity, from chroma or the color information. This is very useful in many applications.\n",
        "\n",
        "In computer vision you often want to separate color components from intensity for various reasons, such as robustness to lighting changes, or removing shadows.\n",
        "\n",
        "Note: HSV is only one of many color spaces that separate color from intensity (See YCbCr, Lab, etc.). HSV is often used simply because the code for converting between RGB and HSV is widely available and can also be easily implemented\n",
        "\n",
        "![](https://www.researchgate.net/profile/Ravindran_G/publication/321126312/figure/fig1/AS:561582682722304@1510903153364/llustration-of-the-HSV-Color-Space-B-Color-Feature-Extraction-Color-feature-is-extracted_W640.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1z1GJLzFpiD"
      },
      "source": [
        "## Read the image\n",
        "img = cv2.imread(\"media/fruit.png\",1)\n",
        "## Display the image\n",
        "cv2_imshow(img) # or plt.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTlokuNsFtmO"
      },
      "source": [
        "# Convert out RGB image to HSV\n",
        "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV )\n",
        "\n",
        "lower_bound = (40, 39, 0)\n",
        "higher_bound = (179, 255,255)\n",
        "\n",
        "# Threshold/mask the img between lower and higher bound\n",
        "mask = cv2.inRange(hsv_img, lower_bound, higher_bound)\n",
        "\n",
        "cv2_imshow(mask) # or plt.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgyfgXsy0Kb7"
      },
      "source": [
        "## Results\n",
        "# Displays the masked result\n",
        "res = cv2.bitwise_and(img,img,mask = mask)\n",
        "cv2_imshow(res) # or plt.imshow(res) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCCkOqAS0KSQ"
      },
      "source": [
        "## erosion and dilation\n",
        "\n",
        "# Define a kernel of ones with shape 5X5\n",
        "kernel = np.ones((5,5))\n",
        "\n",
        "dilation = cv2.dilate(mask, kernel, iterations=1)\n",
        "erosion = cv2.erode(dilation, kernel, iterations=2)\n",
        "dilation = cv2.dilate(erosion, kernel, iterations=2)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.subplot(121),plt.imshow(mask)\n",
        "plt.subplot(122),plt.imshow(dilation)\n",
        "plt.show()\n",
        "\n",
        "mask = dilation.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plELeFYVCq6t"
      },
      "source": [
        "## Contours \n",
        "\n",
        "Contours can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity. The contours are a useful tool for shape analysis and object detection and recognition.\n",
        "\n",
        "For better accuracy, use binary images. So before finding contours, apply threshold or canny edge detection.\n",
        "\n",
        "\n",
        "In OpenCV, finding contours is like finding white object from black background. So remember, object to be found should be white and background should be black.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xjMa3gZDDtT"
      },
      "source": [
        "## Finding contours\n",
        "cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "\n",
        "img_copy = img.copy()\n",
        "cv2.drawContours(img_copy, cnts, -1, (0,255,0), 3)\n",
        "cv2_imshow(img_copy) # or plt.imshow(img_copy) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaKy5mjn0KGO"
      },
      "source": [
        "for cnt in cnts:\n",
        "  # Max are contour and drawing bounding rectangle\n",
        "  x, y, w, h = cv2.boundingRect(cnt)\n",
        "  cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "\n",
        "cv2_imshow(img) # or plt.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIu3GEKnFZvr"
      },
      "source": [
        "## Tracking in a video\n",
        "\n",
        "We can use the concepts we just learned above and apply the same to a video.\n",
        "We are going to try to track the position of the red ball in the below video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vvAxhP1Filv"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('media/track1.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm0L5DKnJEPF"
      },
      "source": [
        "out = cv2.VideoWriter(\n",
        "    \"media/track_out\" + \".avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 10.0,\n",
        "    (1280,720))\n",
        "cap = cv2.VideoCapture(\"media/track1.mp4\")\n",
        "\n",
        "while True:\n",
        "  ## masking\n",
        "  ret,frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  hsv_img = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
        "  mask = cv2.inRange(hsv_img, (169, 97, 84), (179, 255,255))\n",
        "\n",
        "  ## Cleaning up the mask\n",
        "  blur = cv2.GaussianBlur(mask,(5,5),0)\n",
        "  kernel = np.ones((3,3))\n",
        "  erosion = cv2.erode(mask,kernel,iterations=1)\n",
        "  dilation = cv2.dilate(erosion,kernel,iterations=1)\n",
        "  mask = dilation.copy()\n",
        "\n",
        "  ## Finding contours\n",
        "  cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "\n",
        "  if cnts:\n",
        "    # Max area contour and drawing bounding rectangle\n",
        "    C_max = max(cnts,key = cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(C_max)\n",
        "    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "\n",
        "    ## Draw and find circle radius\n",
        "    (x,y),radius = cv2.minEnclosingCircle(C_max)\n",
        "    center = (int(x),int(y))\n",
        "    radius = int(radius)\n",
        "    frame = cv2.circle(frame,center,radius,(0,255,0),2)\n",
        "    #--------------------------------------#\n",
        "\n",
        "  out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sROe5hpPeE8"
      },
      "source": [
        "!ffmpeg -hide_banner -loglevel warning -i media/track_out.avi -vf fps=\"fps=60\" media/track_out.mp4 \n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('media/track_out.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzYRLRSTFBS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}